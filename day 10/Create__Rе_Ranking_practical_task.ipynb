{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG4wvjYyMCkr"
      },
      "source": [
        "**Cross-Encoder Re-Ranking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI1_9dt4MS5A"
      },
      "source": [
        "Install sentence-transformers python library  and import 'CrossEncoder' from this library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "3bSsJe0xL-PT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\artur\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# place your code here\n",
        "from sentence_transformers import CrossEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePIiSGypRk7s"
      },
      "outputs": [],
      "source": [
        "# place your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuT_qlkhRELf"
      },
      "source": [
        "From typing  import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p-eXZD6HSa9p"
      },
      "outputs": [],
      "source": [
        "# place your code here\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuFp9X8fS1-t"
      },
      "source": [
        "Load the pre-trained cross-encoder model 'cross-encoder/ms-marco-MiniLM-L-6-v2' and save the model object to the 'model' variable. To load, use CrossEncoder() with two arguments: the first is the model name as string and the second argument is 'max_length=512'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "Z7mFAH7_VamV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading weights: 100%|██████████| 105/105 [00:00<00:00, 330.82it/s, Materializing param=classifier.weight]                                    \n",
            "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# place your code here\n",
        "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', max_length=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMAY4elYS7Y"
      },
      "source": [
        "Use function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wSED3rWbYEAN"
      },
      "outputs": [],
      "source": [
        "def rerank_documents(\n",
        "    query: str,  documents: List[str],  top_k: int = 10\n",
        ") -> List[Tuple[int, str, float]]:\n",
        "    \"\"\"\n",
        "    Re-rank documents based on relevance to query.\n",
        "    Args:\n",
        "        query: The search query\n",
        "        documents: List of document texts from initial retrieval\n",
        "        top_k: Number of top results to return\n",
        "    Returns:\n",
        "        List of (original_index, document, score) tuples, sorted by relevance\n",
        "    \"\"\"\n",
        "    # Create query-document pairs for the cross-encoder\n",
        "    # Each pair will be scored independently\n",
        "    pairs = [[query, doc] for doc in documents]\n",
        "\n",
        "    # Get relevance scores for all pairs\n",
        "    # The model outputs a single score per pair\n",
        "    scores = model.predict(pairs)\n",
        "\n",
        "    # Combine with original indices and sort by score descending\n",
        "    scored_docs = [\n",
        "        (idx, doc, float(score))\n",
        "        for idx, (doc, score) in enumerate(zip(documents, scores))\n",
        "    ]\n",
        "    scored_docs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    return scored_docs[:top_k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkwSr7FyZVVu"
      },
      "source": [
        "Simulate retrieval results: use the following data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o9a0kiHkeWRQ"
      },
      "outputs": [],
      "source": [
        "retrieved_docs = [\n",
        "        \"Kubernetes pod monitoring requires metrics collection from the kubelet.\",\n",
        "        \"Docker containers can be monitored using cAdvisor metrics.\",\n",
        "        \"To check pod status, use kubectl get pods command.\",\n",
        "        \"Prometheus is commonly used for Kubernetes monitoring.\",\n",
        "        \"Pod resource limits should be set in the deployment spec.\",\n",
        "        \"OneUptime provides real-time Kubernetes monitoring dashboards.\",\n",
        "        \"Container orchestration platforms need observability solutions.\",\n",
        "        \"The kubectl logs command shows container output.\",\n",
        "    ]\n",
        "query = \"How do I monitor Kubernetes pods?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqoLs-IovCFp"
      },
      "source": [
        "Select a value for the k parameter and apply the \"rerank_documents()\" function to the data.\n",
        "Save the returned object to the results variabl."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0i7zeLO2a1Qx"
      },
      "outputs": [],
      "source": [
        "# place your code here.\n",
        "results = rerank_documents(query, retrieved_docs, top_k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOOy9YNatZKl"
      },
      "source": [
        "Using the 'for idx, doc, score in results'    loop, print the values ​​of 'idx', 'doc' and 'score'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PQq-EvBJbY9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-ranked results:\n",
            "Index:  0\n",
            "Score:  6.195793628692627\n",
            "Doc:  Kubernetes pod monitoring requires metrics collection from the kubelet.\n",
            "Index:  5\n",
            "Score:  2.8766818046569824\n",
            "Doc:  OneUptime provides real-time Kubernetes monitoring dashboards.\n",
            "Index:  3\n",
            "Score:  2.8236851692199707\n",
            "Doc:  Prometheus is commonly used for Kubernetes monitoring.\n",
            "Index:  2\n",
            "Score:  0.14170622825622559\n",
            "Doc:  To check pod status, use kubectl get pods command.\n",
            "Index:  7\n",
            "Score:  -8.542131423950195\n",
            "Doc:  The kubectl logs command shows container output.\n"
          ]
        }
      ],
      "source": [
        "print(\"Re-ranked results:\")\n",
        "# place your code here\n",
        "for idx, doc, score in results:\n",
        "    print(\"Index: \", idx)\n",
        "    print(\"Score: \", score)\n",
        "    print(\"Doc: \", doc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
