{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a65516",
   "metadata": {},
   "source": [
    "## üåü Scenario: Content Moderation System\n",
    "\n",
    "### The Problem\n",
    "\n",
    "You've joined a growing tech community platform that has **50,000 users** but only **3 moderators**:\n",
    "- **Sarah** manually reviews posts (6 hours/day, 200+ posts in queue)\n",
    "- **Mike** tries to help users improve content (rarely has time)\n",
    "- **Lisa** identifies harmful content (can't keep up)\n",
    "\n",
    "**Current Issues:**\n",
    "- Takes 5-10 minutes per post to check safety, tone, and grammar manually\n",
    "- Users don't understand why content is rejected\n",
    "- No time to enhance approved content\n",
    "\n",
    "### Your Solution\n",
    "\n",
    "Build an **AI-Powered Content Moderation System** that:\n",
    "\n",
    "1. **Classifies** content type (social media post / article / comment)\n",
    "2. **Analyzes** safety, tone, and grammar **in parallel**\n",
    "3. **Scores** and decides: approve or reject\n",
    "4. **Enhances** approved content automatically\n",
    "5. **Provides feedback** to users\n",
    "\n",
    "**Expected Impact:** Reduce moderation time from 5-10 minutes to 30 seconds per post!\n",
    "\n",
    "### Example Test Cases\n",
    "\n",
    "Your system should handle:\n",
    "\n",
    "**‚úÖ Good Content (needs enhancement):**\n",
    "```\n",
    "just finished reading an amzing book about AI ethics! \n",
    "its really make me think about how we build responsible systems.\n",
    "```\n",
    "‚Üí Approve, fix grammar, enhance\n",
    "\n",
    "**‚ö†Ô∏è Problematic Content:**\n",
    "```\n",
    "I hate this stupid product! Complete waste of money.\n",
    "```\n",
    "‚Üí Flag for aggressive language, suggest constructive rephrasing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670706a",
   "metadata": {},
   "source": [
    "## üìã Challenge Overview\n",
    "\n",
    "### Your Mission\n",
    "\n",
    "Build an **AI-Powered Content Moderation & Enhancement System** that:\n",
    "1. Analyzes user-submitted content (text posts)\n",
    "2. Moderates for safety and quality\n",
    "3. Provides improvement suggestions\n",
    "4. Enhances approved content\n",
    "\n",
    "### Why This Challenge?\n",
    "\n",
    "This challenge combines **multiple agentic patterns** in a realistic scenario:\n",
    "- **Routing**: Classify content type (social media post, article, comment)\n",
    "- **Evaluator-Optimizer**: Assess content quality and iterate improvements\n",
    "- **Parallelization**: Analyze multiple aspects simultaneously (tone, safety, grammar)\n",
    "- **Orchestrator-Worker**: Coordinate the full moderation pipeline\n",
    "- **Prompt Chaining**: Transform raw content through moderation ‚Üí enhancement ‚Üí finalization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b892a",
   "metadata": {},
   "source": [
    "## üéì Part 1: Framework Selection & Justification\n",
    "\n",
    "### Task 1.1: Choose Your Framework\n",
    "\n",
    "**Instructions:**\n",
    "1. Review the 4 frameworks you learned\n",
    "2. Select ONE framework for this challenge\n",
    "3. Write a justification (150-200 words) explaining:\n",
    "   - Why you chose this framework\n",
    "   - What strengths make it suitable for this challenge\n",
    "   - What trade-offs you considered\n",
    "   - How its features align with the challenge requirements\n",
    "\n",
    "**Available Frameworks:**\n",
    "- CrewAI: Role-based agents, sequential/hierarchical processes\n",
    "- LangGraph: Graph-based state management, conditional routing\n",
    "- LlamaIndex: Data-centric, built-in RAG capabilities\n",
    "- smolagents: Lightweight, tool-focused, minimal dependencies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74711a",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR FRAMEWORK SELECTION\n",
    "\n",
    "**Selected Framework:** [WRITE YOUR CHOICE HERE]\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "[WRITE YOUR JUSTIFICATION HERE - 150-250 words]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806e60a",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Part 2: Setup & Configuration\n",
    "\n",
    "### Task 2.1: Install Dependencies\n",
    "\n",
    "Install your chosen framework and configure your API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "964c0d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langgraph in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (1.0.9)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (1.1.10)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (1.2.16)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.8 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (1.0.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (0.3.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (2.11.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.11.5 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
      "Requirement already satisfied: openai<3.0.0,>=2.20.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_openai) (2.24.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (0.7.7)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.1->langgraph) (0.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2026.1.15)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_community) (2.0.47)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain_community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\artur\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai<3.0.0,>=2.20.0->langchain_openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install your chosen framework and dependencies\n",
    "# Your code here:\n",
    "!pip install -U langgraph langchain_openai langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43390fbb",
   "metadata": {},
   "source": [
    "### Task 2.2: Configure API Keys & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaf94ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured. Model 'gpt-4o' is ready for orchestration.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0,\n",
    "    base_url=os.environ[\"OPENAI_BASE_URL\"]\n",
    ")\n",
    "\n",
    "print(\"Environment configured. Model 'gpt-4o' is ready for orchestration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a4800",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèóÔ∏è Part 3: Implementation\n",
    "\n",
    "Build your **Content Moderation & Enhancement System** by implementing the following components:\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "```\n",
    "User Content Input\n",
    "      |\n",
    "      v\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Router Agent   ‚îÇ ‚îÄ‚îÄ> Classify: Social Media / Article / Comment\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         |\n",
    "         v\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Parallel Analysis       ‚îÇ\n",
    "‚îÇ  - Safety Check Agent   ‚îÇ ‚îÄ‚îÄ> Detect harmful content\n",
    "‚îÇ  - Tone Analyzer Agent  ‚îÇ ‚îÄ‚îÄ> Assess sentiment/tone\n",
    "‚îÇ  - Grammar Checker      ‚îÇ ‚îÄ‚îÄ> Identify language issues\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         |\n",
    "         v\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Evaluator Agent         ‚îÇ ‚îÄ‚îÄ> Aggregate findings, score content\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         |\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    v          v\n",
    "  REJECT    APPROVE\n",
    "            |\n",
    "            v\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ  Optimizer    ‚îÇ ‚îÄ‚îÄ> Suggest improvements\n",
    "    ‚îÇ  Agent        ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            |\n",
    "            v\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ  Enhancer     ‚îÇ ‚îÄ‚îÄ> Apply improvements\n",
    "    ‚îÇ  Agent        ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            |\n",
    "            v\n",
    "    Final Enhanced Content\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef252339",
   "metadata": {},
   "source": [
    "### Task 3.1: Router Agent (Routing Pattern)\n",
    "\n",
    "**Requirements:**\n",
    "- Create a router that classifies content into: \"social_media\", \"article\", or \"comment\"\n",
    "- Route should be based on length, structure, and style\n",
    "- Return the classification decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4091fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Router Agent\n",
    "# This agent analyzes content and classifies it\n",
    "\n",
    "# Your code here:\n",
    "from typing import TypedDict, List, Optional\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "class ModerationState(TypedDict):\n",
    "    content: str\n",
    "    content_type: str\n",
    "    safety_report: str\n",
    "    tone_report: str\n",
    "    grammar_report: str\n",
    "    score: int\n",
    "    decision: str \n",
    "    suggestions: str\n",
    "    final_content: str\n",
    "\n",
    "\n",
    "def router_agent(state: ModerationState):\n",
    "    \"\"\"Classifies content into social_media, article, or comment.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following user content and classify it into one of these three categories:\n",
    "    1. 'social_media': Short, informal, often uses hashtags or casual language.\n",
    "    2. 'article': Long-form, structured, professional, or educational.\n",
    "    3. 'comment': Brief responses, usually reactive or conversational.\n",
    "    \n",
    "    Content: \"{state['content']}\"\n",
    "    \n",
    "    Return ONLY a JSON object with the key \"classification\".\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    result = json.loads(response.content.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    \n",
    "    print(f\"--- ROUTER: Classified content as {result['classification']} ---\")\n",
    "    \n",
    "    return {\"content_type\": result['classification']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040dd1f0",
   "metadata": {},
   "source": [
    "### Task 3.2: Parallel Analysis Agents (Parallelization Pattern)\n",
    "\n",
    "**Requirements:**\n",
    "- Implement 3 agents that run in parallel:\n",
    "  1. **Safety Checker**: Detect toxic, harmful, or inappropriate content\n",
    "  2. **Tone Analyzer**: Assess sentiment (positive/negative/neutral) and professionalism\n",
    "  3. **Grammar Checker**: Identify spelling, grammar, and clarity issues\n",
    "- Each agent should return a structured assessment\n",
    "- Execute them concurrently for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e5ee440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Parallel Analysis Agents\n",
    "# These agents analyze different aspects simultaneously\n",
    "\n",
    "# Your code here:\n",
    "def safety_checker(state: ModerationState):\n",
    "    \"\"\"Detects toxic or harmful content.\"\"\"\n",
    "    prompt = f\"Analyze this {state['content_type']} for safety. Is it toxic, hateful, or harmful?\\nContent: {state['content']}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"safety_report\": response.content}\n",
    "\n",
    "def tone_analyzer(state: ModerationState):\n",
    "    \"\"\"Assesses sentiment and professionalism.\"\"\"\n",
    "    prompt = f\"Analyze the tone of this {state['content_type']}. Is it positive, negative, or neutral? Is it professional?\\nContent: {state['content']}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"tone_report\": response.content}\n",
    "\n",
    "def grammar_checker(state: ModerationState):\n",
    "    \"\"\"Identifies spelling and grammar issues.\"\"\"\n",
    "    prompt = f\"Identify grammar and spelling issues in this {state['content_type']}. Do not fix them yet, just list them.\\nContent: {state['content']}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"grammar_report\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25123cc2",
   "metadata": {},
   "source": [
    "### Task 3.3: Evaluator Agent (Evaluator-Optimizer Pattern - Part 1)\n",
    "\n",
    "**Requirements:**\n",
    "- Aggregate results from the 3 parallel agents\n",
    "- Calculate an overall content quality score (0-100)\n",
    "- Make a decision: APPROVE (score ‚â• 70) or REJECT (score < 70)\n",
    "- For approved content, provide specific improvement suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a4d2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Evaluator Agent\n",
    "# This agent aggregates findings and makes decisions\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "def evaluator_agent(state: ModerationState):\n",
    "    \"\"\"Aggregates findings and scores content quality.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Content Moderator. Review these three reports and provide a final evaluation:\n",
    "    \n",
    "    1. Safety: {state['safety_report']}\n",
    "    2. Tone: {state['tone_report']}\n",
    "    3. Grammar: {state['grammar_report']}\n",
    "    \n",
    "    Original Content: \"{state['content']}\"\n",
    "    \n",
    "    Decision Criteria:\n",
    "    - Score 0-100 based on quality and safety.\n",
    "    - If Safety identifies harmful content, Score MUST be below 50.\n",
    "    - APPROVE if score >= 70, otherwise REJECT.\n",
    "    \n",
    "    Return ONLY a JSON object with:\n",
    "    \"score\": (int),\n",
    "    \"decision\": \"APPROVE\" or \"REJECT\",\n",
    "    \"suggestions\": \"List specific improvements if approved, or reasons if rejected\"\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = json.loads(response.content.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    \n",
    "    print(f\"--- EVALUATOR: Score {result['score']} | Decision: {result['decision']} ---\")\n",
    "    \n",
    "    return {\n",
    "        \"score\": result['score'],\n",
    "        \"decision\": result['decision'],\n",
    "        \"suggestions\": result['suggestions']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9d7b8",
   "metadata": {},
   "source": [
    "### Task 3.4: Optimizer & Enhancer Agents (Prompt Chaining + Evaluator-Optimizer)\n",
    "\n",
    "**Requirements:**\n",
    "- **Optimizer Agent**: Generate specific improvements based on evaluator feedback\n",
    "- **Enhancer Agent**: Apply improvements to create an enhanced version\n",
    "- Implement as a chain: Original Content ‚Üí Optimizer ‚Üí Enhancer ‚Üí Final Content\n",
    "- (Optional) Add a re-evaluation loop if initial enhancement score is still low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cb7eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Optimizer and Enhancer Agents\n",
    "# These agents improve content based on feedback\n",
    "\n",
    "# Your code here:\n",
    "def optimizer_agent(state: ModerationState):\n",
    "    \"\"\"Generates an optimization strategy based on evaluator feedback.\"\"\"\n",
    "    if state['decision'] == \"REJECT\":\n",
    "        return {\"suggestions\": \"N/A - Content Rejected\"}\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "    Based on this feedback: \"{state['suggestions']}\", \n",
    "    create a specific plan to enhance the following content while keeping its original meaning.\n",
    "    Content: \"{state['content']}\"\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"suggestions\": response.content}\n",
    "\n",
    "def enhancer_agent(state: ModerationState):\n",
    "    \"\"\"Applies the optimization plan to create the final version.\"\"\"\n",
    "    if state['decision'] == \"REJECT\":\n",
    "        return {\"final_content\": state['content']}\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "    Rewrite the following content based on this improvement plan: \"{state['suggestions']}\"\n",
    "    Original Content: \"{state['content']}\"\n",
    "    \n",
    "    Provide ONLY the final enhanced text.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"final_content\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263dc88",
   "metadata": {},
   "source": [
    "### Task 3.5: Orchestrator (Orchestrator-Worker Pattern)\n",
    "\n",
    "**Requirements:**\n",
    "- Create a master orchestrator that coordinates the entire pipeline:\n",
    "  1. Route content type\n",
    "  2. Run parallel analysis\n",
    "  3. Evaluate and decide\n",
    "  4. If approved, optimize and enhance\n",
    "  5. Return final result with metadata\n",
    "- Handle both approval and rejection cases\n",
    "- Provide clear logging of each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f260c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Orchestrator\n",
    "# This coordinates the entire moderation pipeline\n",
    "\n",
    "# Your code here:\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(ModerationState)\n",
    "\n",
    "workflow.add_node(\"classify\", router_agent)\n",
    "workflow.add_node(\"safety\", safety_checker)\n",
    "workflow.add_node(\"tone\", tone_analyzer)\n",
    "workflow.add_node(\"grammar\", grammar_checker)\n",
    "workflow.add_node(\"evaluate\", evaluator_agent)\n",
    "workflow.add_node(\"optimize\", optimizer_agent)\n",
    "workflow.add_node(\"enhance\", enhancer_agent)\n",
    "\n",
    "workflow.set_entry_point(\"classify\")\n",
    "\n",
    "workflow.add_edge(\"classify\", \"safety\")\n",
    "workflow.add_edge(\"classify\", \"tone\")\n",
    "workflow.add_edge(\"classify\", \"grammar\")\n",
    "\n",
    "workflow.add_edge(\"safety\", \"evaluate\")\n",
    "workflow.add_edge(\"tone\", \"evaluate\")\n",
    "workflow.add_edge(\"grammar\", \"evaluate\")\n",
    "\n",
    "def routing_logic(state: ModerationState):\n",
    "    return \"optimize\" if state[\"decision\"] == \"APPROVE\" else END\n",
    "\n",
    "workflow.add_conditional_edges(\"evaluate\", routing_logic)\n",
    "\n",
    "workflow.add_edge(\"optimize\", \"enhance\")\n",
    "workflow.add_edge(\"enhance\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac006f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Part 4: Testing\n",
    "\n",
    "### Task 4.1: Test with Sample Content\n",
    "\n",
    "Test your system with the provided examples representing different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc8a6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING: Social Media Post with Errors\n",
      "======================================================================\n",
      "--- ROUTER: Classified content as social_media ---\n",
      "--- EVALUATOR: Score 85 | Decision: APPROVE ---\n",
      "1. CLASSIFICATION: SOCIAL_MEDIA\n",
      "\n",
      "2. ANALYSIS RESULTS:\n",
      "   - Safety:  The content you provided is positive and constructive. It expresses enthusiasm about a book on AI ethics and encourages ...\n",
      "   - Tone:    The tone of the social media post is positive. The user expresses enthusiasm and appreciation for the book about AI ethi...\n",
      "   - Grammar: 1. \"amzing\" should be \"amazing\" (spelling error)  \n",
      "2. \"its\" should be \"it's\" (missing apostrophe for contraction)  \n",
      "3. \"...\n",
      "\n",
      "3. EVALUATION:\n",
      "   - Score:    85/100\n",
      "   - Decision: APPROVE\n",
      "\n",
      "4. ENHANCED VERSION:\n",
      "   Just finished reading an amazing book about AI ethics!  \n",
      "It really makes me think about how we build responsible systems.  \n",
      "Highly recommend it to anyone in tech!\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Professional Article\n",
      "======================================================================\n",
      "--- ROUTER: Classified content as article ---\n",
      "--- EVALUATOR: Score 90 | Decision: APPROVE ---\n",
      "1. CLASSIFICATION: ARTICLE\n",
      "\n",
      "2. ANALYSIS RESULTS:\n",
      "   - Safety:  The article is safe. It is informative and discusses the impact of machine learning in healthcare, highlighting both ben...\n",
      "   - Tone:    The tone of the article is generally neutral with a slight positive inclination. It acknowledges the transformative impa...\n",
      "   - Grammar: 1. Missing period at the end of the third sentence (\"However, concerns about data privacy and algorithmic bias remain si...\n",
      "\n",
      "3. EVALUATION:\n",
      "   - Score:    90/100\n",
      "   - Decision: APPROVE\n",
      "\n",
      "4. ENHANCED VERSION:\n",
      "   Machine learning algorithms have transformed the healthcare industry over the past decade. These systems now assist in diagnosis, treatment planning, and patient monitoring. However, concerns about data privacy and algorithmic bias remain significant challenges. Researchers and practitioners must address these issues to ensure equitable healthcare delivery.\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Short Comment\n",
      "======================================================================\n",
      "--- ROUTER: Classified content as comment ---\n",
      "--- EVALUATOR: Score 75 | Decision: APPROVE ---\n",
      "1. CLASSIFICATION: COMMENT\n",
      "\n",
      "2. ANALYSIS RESULTS:\n",
      "   - Safety:  The comment is positive and supportive. It is not toxic, hateful, or harmful....\n",
      "   - Tone:    The tone of the comment is positive, as it expresses agreement and enthusiasm (\"this is grate! i totally agree...\"). How...\n",
      "   - Grammar: 1. \"grate\" should be \"great\" (spelling error)  \n",
      "2. The first word \"this\" should be capitalized (\"This\")  \n",
      "3. The pronoun...\n",
      "\n",
      "3. EVALUATION:\n",
      "   - Score:    75/100\n",
      "   - Decision: APPROVE\n",
      "\n",
      "4. ENHANCED VERSION:\n",
      "   This is great! I totally agree with your point about AI safety. It's so important.\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Potentially Problematic Content\n",
      "======================================================================\n",
      "--- ROUTER: Classified content as comment ---\n",
      "--- EVALUATOR: Score 65 | Decision: REJECT ---\n",
      "1. CLASSIFICATION: COMMENT\n",
      "\n",
      "2. ANALYSIS RESULTS:\n",
      "   - Safety:  The comment expresses strong negative opinions but does not contain toxic language, hate speech, or harmful content dire...\n",
      "   - Tone:    The tone of the comment is negative. It expresses strong dissatisfaction and frustration with both the product and the c...\n",
      "   - Grammar: 1. The phrase \"Complete waste of money.\" is a sentence fragment.\n",
      "2. The word \"them\" is ambiguous because it refers to \"t...\n",
      "\n",
      "3. EVALUATION:\n",
      "   - Score:    65/100\n",
      "   - Decision: REJECT\n",
      "\n",
      "4. FEEDBACK:\n",
      "   The comment is negative and uses harsh, emotionally charged language that lacks professionalism and constructive feedback. It contains sentence fragments and ambiguous pronoun usage. To improve, the user should provide polite, clear, and constructive criticism with complete sentences and correct pronoun agreement.\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Clean social media post (should be approved and enhanced)\n",
    "test_content_1 = \"\"\"\n",
    "just finished reading an amzing book about AI ethics! \n",
    "its really make me think about how we build responsible systems. \n",
    "highly recomend it to anyone in tech!\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 2: Professional article excerpt (should be approved, might need minor fixes)\n",
    "test_content_2 = \"\"\"\n",
    "Machine learning algorithms have transformed the healthcare industry over the past decade.\n",
    "These systems now assist in diagnosis, treatment planning, and patient monitoring.\n",
    "However, concerns about data privacy and algorithmic bias remain significant challenges\n",
    "that researchers and practitioners must address to ensure equitable healthcare delivery.\n",
    "\"\"\"\n",
    "\n",
    "# Test Case 3: Short comment with grammar issues (should be approved but needs enhancement)\n",
    "test_content_3 = \"this is grate! i totally agree with ur point about ai safety its so important\"\n",
    "\n",
    "# Test Case 4: Content with potential safety issues (might be rejected or flagged)\n",
    "test_content_4 = \"\"\"\n",
    "I hate this stupid product! Complete waste of money. \n",
    "The company is terrible and everyone should avoid them.\n",
    "\"\"\"\n",
    "\n",
    "test_cases = [\n",
    "    (\"Social Media Post with Errors\", test_content_1),\n",
    "    (\"Professional Article\", test_content_2),\n",
    "    (\"Short Comment\", test_content_3),\n",
    "    (\"Potentially Problematic Content\", test_content_4)\n",
    "]\n",
    "\n",
    "for title, content in test_cases:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {title}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Initialize state for the orchestrator\n",
    "    inputs = {\"content\": content.strip()}\n",
    "    \n",
    "    # Run the graph\n",
    "    final_state = app.invoke(inputs)\n",
    "    \n",
    "    # Display the results\n",
    "    print(f\"1. CLASSIFICATION: {final_state.get('content_type', 'N/A').upper()}\")\n",
    "    print(f\"\\n2. ANALYSIS RESULTS:\")\n",
    "    print(f\"   - Safety:  {final_state.get('safety_report', 'N/A')[:120]}...\")\n",
    "    print(f\"   - Tone:    {final_state.get('tone_report', 'N/A')[:120]}...\")\n",
    "    print(f\"   - Grammar: {final_state.get('grammar_report', 'N/A')[:120]}...\")\n",
    "    \n",
    "    print(f\"\\n3. EVALUATION:\")\n",
    "    print(f\"   - Score:    {final_state.get('score', 0)}/100\")\n",
    "    print(f\"   - Decision: {final_state.get('decision', 'N/A')}\")\n",
    "    \n",
    "    if final_state.get('decision') == \"APPROVE\":\n",
    "        print(f\"\\n4. ENHANCED VERSION:\")\n",
    "        print(f\"   {final_state.get('final_content')}\")\n",
    "    else:\n",
    "        print(f\"\\n4. FEEDBACK:\")\n",
    "        print(f\"   {final_state.get('suggestions')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629d748",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 5: Reflection & Analysis\n",
    "\n",
    "### Task 5.1: Pattern Usage Documentation\n",
    "\n",
    "Document how you used each agentic pattern in your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ced56",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR PATTERN USAGE ANALYSIS\n",
    "\n",
    "**1. Routing Pattern:**\n",
    "- Where used: [this was used at the very beginning with the router_agent]\n",
    "- Why effective: [figure out if a text is a short comment or a long article first, the other agents know whether to be super strict or more relaxed about the tone and style.]\n",
    "\n",
    "**2. Parallelization Pattern:**\n",
    "- Where used: [safety_checker, tone_analyzer, and grammar_checker]\n",
    "- Why effective: [its much faster than doing one check after another]\n",
    "- Performance benefit: [it cuts down the waiting time for the user]\n",
    "\n",
    "**3. Evaluator-Optimizer Pattern:**\n",
    "- Where used: [this was the \"quality control\" step where the Evaluator looked at all the reports and decided if the post was good enough to publish]\n",
    "- How feedback loop works: [evaluator gives notes on whats wrong. If the post passes, the optimizer uses those notes to plan out exactly how to fix the issues]\n",
    "\n",
    "**4. Prompt Chaining Pattern:**\n",
    "- Where used: [for the \"Approved\" posts]\n",
    "- Stages in chain: [1 Read the feedback. 2 Plan the improvements. 3 Write the corrected version]\n",
    "\n",
    "**5. Orchestrator-Worker Pattern:**\n",
    "- How orchestration is managed: [LangGraph acted as manager of the whole system.]\n",
    "- Worker coordination: [manager makes sure safety, tone, grammar do their jobs first, then hands their notes to the evaluator to make the final call]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e9367",
   "metadata": {},
   "source": [
    "### Task 5.2: Challenges & Solutions\n",
    "\n",
    "Reflect on difficulties you encountered and how you solved them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80990919",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR CHALLENGES & SOLUTIONS\n",
    "\n",
    "**Challenge 1:**\n",
    "- Problem: [multiple \"Invalid API Key\" error]\n",
    "- Solution: [cleared variables, added .env and used getpass to re enter key]\n",
    "\n",
    "**Challenge 2:**\n",
    "- Problem: [it was tricky to make sure the safety, tone, and grammar all finished their work before the Evaluator started.]\n",
    "- Solution: [used LangGraph‚Äôs state management to \"join\" the branches]\n",
    "\n",
    "**Challenge 3:**\n",
    "- Problem: [DESCRIBE]\n",
    "- Solution: [EXPLAIN]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d026b",
   "metadata": {},
   "source": [
    "### Task 5.3: Framework Reflection\n",
    "\n",
    "Now that you've completed the challenge, reflect on your framework choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d60ee",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è YOUR FRAMEWORK REFLECTION\n",
    "\n",
    "**What worked well with your chosen framework?**\n",
    "\n",
    "[LangGraph made it really easy to see how the data moves from one step to the next.]\n",
    "\n",
    "**What was difficult or limiting?**\n",
    "\n",
    "[The state was the hardest part to get right. In LangGraph, you have to define exactly what data is being passed around in a dictionary. If one agent (node) forgets to return a value or uses the wrong key name, the whole system crashes]\n",
    "\n",
    "**Would you choose the same framework again? Why or why not?**\n",
    "\n",
    "[yes,  It is good way for building agents. It was a little hard at first because no experience but once you get the hang of it, it‚Äôs actually super chill. ]\n",
    "\n",
    "**What would you do differently next time?**\n",
    "\n",
    "[YOUR RESPONSE HERE]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b9fdc",
   "metadata": {},
   "source": [
    "## üéÅ Bonus Challenges (Optional)\n",
    "\n",
    "If you want to go further, try these enhancements:\n",
    "\n",
    "### Bonus 1: Multi-Language Support\n",
    "- Add a language detection agent\n",
    "- Support content in at least 3 languages\n",
    "\n",
    "### Bonus 2: Customizable Moderation Rules\n",
    "- Allow users to set content policy preferences\n",
    "- Adjust safety thresholds based on use case (e.g., strict for children's content)\n",
    "\n",
    "### Bonus 3: Performance Optimization\n",
    "- Measure execution time for each component\n",
    "- Implement caching for repeated content\n",
    "- Optimize parallel execution\n",
    "\n",
    "### Bonus 4: Explainability Dashboard\n",
    "- Create a visualization showing:\n",
    "  - Agent decision flow\n",
    "  - Confidence scores at each stage\n",
    "  - Before/after content comparison\n",
    "\n",
    "### Bonus 5: Iterative Re-evaluation\n",
    "- If enhanced content scores < 90, run another optimization loop\n",
    "- Limit to maximum 3 iterations to prevent infinite loops\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d7da115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Implement your bonus challenges here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78315590",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Evaluation Criteria\n",
    "\n",
    "Your implementation will be assessed on:\n",
    "\n",
    "### Functionality (20 points)\n",
    "- ‚úÖ Router correctly classifies content types\n",
    "- ‚úÖ Parallel agents execute concurrently\n",
    "- ‚úÖ Evaluator makes appropriate approve/reject decisions\n",
    "- ‚úÖ Enhancement chain improves content quality\n",
    "- ‚úÖ Orchestrator coordinates full pipeline\n",
    "\n",
    "### Pattern Implementation (20 points)\n",
    "- ‚úÖ Routing pattern clearly implemented\n",
    "- ‚úÖ Parallelization working correctly\n",
    "- ‚úÖ Evaluator-optimizer feedback loop functional\n",
    "- ‚úÖ Prompt chaining evident in enhancement\n",
    "- ‚úÖ Orchestrator-worker hierarchy clear\n",
    "\n",
    "### Code Quality (20 points)\n",
    "- ‚úÖ Clean, readable code\n",
    "- ‚úÖ Proper error handling\n",
    "- ‚úÖ Good documentation/comments\n",
    "- ‚úÖ Framework best practices followed\n",
    "\n",
    "### Reflection & Analysis ( **40 points** )\n",
    "- ‚úÖ Thoughtful framework justification\n",
    "- ‚úÖ Clear pattern usage documentation\n",
    "- ‚úÖ Honest challenge/solution discussion\n",
    "- ‚úÖ Insightful framework reflection\n",
    "\n",
    "### Bonus Points (up to 10 extra points)\n",
    "- Optional challenges attempted and completed\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Conclusion\n",
    "\n",
    "Congratulations on completing this challenge! You've built a sophisticated multi-agent system that combines multiple agentic patterns in a real-world scenario.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "Through this challenge, you've learned:\n",
    "- How to select appropriate frameworks for specific tasks\n",
    "- How to combine multiple agentic patterns effectively\n",
    "- How to design complex multi-agent systems\n",
    "- How to handle real-world challenges in agent development\n",
    "- How to evaluate and reflect on your architectural decisions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment**: Try implementing this challenge with a different framework\n",
    "2. **Extend**: Add more sophisticated features (RAG, custom tools, memory)\n",
    "3. **Deploy**: Consider how you'd productionize this system\n",
    "4. **Share**: Document your learnings and share with the community\n",
    "\n",
    "Keep building, keep learning, and keep pushing the boundaries of what's possible with agentic systems! üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding!** üíª‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
