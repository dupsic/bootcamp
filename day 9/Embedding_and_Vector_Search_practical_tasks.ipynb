{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F96VRX22-IkX"
      },
      "source": [
        "#**Create local vector embeddings using sentens-transformer python library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGYeMFL2bojw"
      },
      "source": [
        "##**GOAL: to embed text sentences and perform semantic searches using your own Python code.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOPrcTxuFWJl"
      },
      "source": [
        "There are many pre-trained embedding models available on Hugging Face that you can use to create vector embeddings.\n",
        "Sentence Transformers (SBERT) is a library that makes it easy to use these models for vector embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsqP-DgCGHcB"
      },
      "source": [
        "Use pip  to install  'sentence_transformers' library  and import  'SentenceTransformer model loader' from this library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "ZEGQgMdBFglD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\artur\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\artur\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\artur\\AppData\\Roaming\\Python\\Python313\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# place your code here\n",
        "# !pip install pinecone-client sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY-ID8AfHKYX"
      },
      "source": [
        "Load the 'paraphrase-MiniLM-L6-v2' model  from HuggingFace resource  using the  SentenceTransformer( *model-name* )  and store the reference to the model object in the 'model' variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "m2ob6UwMMThc"
      },
      "outputs": [],
      "source": [
        "# place your code here\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6pgQE3aMkK_"
      },
      "source": [
        "After loading the model, call the 'encode()' method on the model object to create a vector representation of a specific text sentence. Use your own text string  as the parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxlctyNHZVtJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 4.69190687e-01, -4.88688290e-01,  1.09071419e-01,  1.23868749e-01,\n",
              "        1.24341123e-01,  1.68796688e-01,  2.32297301e-01, -3.02375704e-01,\n",
              "       -2.07809776e-01, -1.32390246e-01, -4.31264579e-01, -5.63790143e-01,\n",
              "       -3.19337666e-01, -1.78913102e-01, -5.78233711e-02, -4.39157598e-02,\n",
              "        6.24780059e-01, -2.45563909e-01,  3.73536617e-01, -6.46496534e-01,\n",
              "       -3.24345052e-01,  2.98268437e-01,  2.12053675e-02,  4.11392674e-02,\n",
              "       -4.25067514e-01,  7.96129927e-02, -1.79599464e-01,  4.14337069e-01,\n",
              "        6.56150430e-02, -7.86581412e-02,  5.48811108e-02,  8.67695138e-02,\n",
              "       -4.45220247e-03, -2.76678920e-01, -4.28922653e-01,  3.96368027e-01,\n",
              "        1.90284058e-01, -3.30392301e-01, -8.87061283e-02,  2.44920924e-01,\n",
              "        1.13868907e-01, -1.14237554e-01,  2.77632713e-01, -6.78310404e-04,\n",
              "       -3.19213361e-01,  1.68152735e-01, -1.15472287e-01,  3.43190223e-01,\n",
              "        5.14081836e-01,  2.15411723e-01,  6.53592467e-01, -4.12587345e-01,\n",
              "        3.88136089e-01, -2.54179925e-01,  2.31845006e-02,  2.89735436e-01,\n",
              "       -7.80178932e-04, -1.75624862e-01,  2.19785035e-01,  1.04090445e-01,\n",
              "       -1.11490801e-01, -1.96717516e-01, -5.29803261e-02, -1.31653687e-02,\n",
              "       -3.83593023e-01, -5.62984347e-01, -5.53236604e-01,  7.87773654e-02,\n",
              "        2.48437405e-01, -3.34469557e-01, -5.04810095e-01,  1.62587360e-01,\n",
              "        6.86805665e-01, -1.91082776e-01, -2.30525672e-01,  4.92281735e-01,\n",
              "       -9.22311619e-02, -6.41263783e-01,  3.22892182e-02, -2.13647723e-01,\n",
              "        9.38123167e-02, -1.92748353e-01,  1.95505530e-01, -1.45298436e-01,\n",
              "        5.52638829e-01,  7.57631510e-02,  6.81263506e-02,  5.10858774e-01,\n",
              "       -8.93241912e-02,  4.12876159e-02, -2.74169952e-01,  4.12700921e-01,\n",
              "       -3.55829954e-01, -4.69920427e-01, -9.26465765e-02,  3.30409080e-01,\n",
              "       -1.69304591e-02, -4.88926113e-01,  4.69067842e-02,  2.65937358e-01,\n",
              "        8.22245702e-02, -2.17489585e-01,  2.65021503e-01,  5.58797494e-02,\n",
              "        2.13608891e-02, -9.24673975e-02, -4.61532056e-01, -3.41655880e-01,\n",
              "        7.24185705e-02, -4.07086015e-01,  6.06670394e-04, -1.06362231e-01,\n",
              "        3.41669649e-01, -4.26355749e-02, -2.94044316e-01,  3.53842854e-01,\n",
              "        1.21909760e-01, -1.92176208e-01,  4.11478043e-01, -1.73376292e-01,\n",
              "       -3.05838346e-01, -1.69679582e-01,  2.12226678e-02, -1.61717609e-01,\n",
              "       -1.76466834e-02, -3.02928060e-01, -1.08317681e-01, -7.51255825e-02,\n",
              "        1.39523312e-01,  1.75914854e-01,  1.78449064e-01, -3.05547148e-01,\n",
              "        2.33971983e-01, -3.23061794e-01, -1.51233107e-01,  5.97679615e-02,\n",
              "        3.12987179e-01,  1.18163541e-01,  2.43761361e-01, -1.53195247e-01,\n",
              "        1.38721079e-01, -2.16595262e-01,  5.74257910e-01, -3.62302631e-01,\n",
              "        1.99078262e-01, -2.59140372e-01, -1.46994472e-01, -1.79931089e-01,\n",
              "        3.67695950e-02, -7.11710528e-02, -1.02177069e-01,  2.88337171e-01,\n",
              "        1.00834571e-01, -4.23305541e-01,  5.05221263e-02,  4.04005200e-01,\n",
              "        3.29491585e-01, -1.77699216e-02,  3.12143624e-01, -3.68120462e-01,\n",
              "       -2.71433651e-01,  6.71684295e-02, -7.66334534e-02, -2.41031498e-01,\n",
              "       -3.56777430e-01,  1.98658645e-01,  6.88311607e-02, -4.85163480e-02,\n",
              "       -4.01827514e-01, -4.42899793e-01, -4.99411076e-01, -1.25041947e-01,\n",
              "       -8.26996863e-02,  2.54621893e-01, -1.77920938e-01,  1.99113384e-01,\n",
              "        3.12135458e-01, -2.84616590e-01,  1.93510249e-01, -1.62120759e-01,\n",
              "        3.80772017e-02,  3.84635963e-02,  1.48607448e-01,  1.25586599e-01,\n",
              "        2.14148045e-01,  1.58689111e-01,  5.82394972e-02, -1.64238568e-02,\n",
              "       -1.50459437e-02, -1.98703688e-02, -1.04305893e-01, -2.47247577e-01,\n",
              "        4.14734602e-01, -9.51382145e-03,  2.83478975e-01,  2.66457886e-01,\n",
              "       -6.63671046e-02, -2.37689480e-01,  3.69639814e-01,  4.66873676e-01,\n",
              "       -2.56538630e-01, -2.72718787e-01,  2.32228950e-01,  7.24454373e-02,\n",
              "        3.43578577e-01, -2.47294724e-01,  1.45915985e-01,  3.33261371e-01,\n",
              "        5.55528998e-01,  3.30997348e-01,  2.66857356e-01,  9.46388245e-02,\n",
              "        4.47365731e-01, -2.52216846e-01,  4.50573973e-02,  2.08107457e-02,\n",
              "       -8.23526382e-02,  1.35265216e-01,  5.82175143e-02,  1.93176001e-01,\n",
              "        5.10764495e-03,  8.18515942e-02, -5.35837784e-02, -9.29052830e-02,\n",
              "        3.81824970e-02,  6.62059560e-02, -1.01688452e-01,  3.25302273e-01,\n",
              "        4.38661464e-02,  4.26541179e-01, -1.92870237e-02, -4.74571250e-03,\n",
              "       -1.88007057e-01,  1.28637344e-01, -4.10631627e-01,  9.22801048e-02,\n",
              "        1.16974294e-01,  1.30695224e-01,  2.77700007e-01, -5.66796124e-01,\n",
              "       -2.75734216e-01,  6.65347040e-01,  3.44114482e-01,  2.65908062e-01,\n",
              "        1.60304215e-02,  1.34275347e-01, -5.01835883e-01,  1.98355138e-01,\n",
              "       -2.44001657e-01, -1.92463677e-02,  1.15187615e-01,  6.61773443e-01,\n",
              "       -2.96797156e-01, -1.98595122e-01, -2.26779610e-01,  2.95591187e-02,\n",
              "       -4.28232849e-01, -5.13675928e-01,  1.37689635e-01,  3.45835656e-01,\n",
              "        1.89996764e-01, -4.14519966e-01,  1.04068100e-01,  3.52631330e-01,\n",
              "        7.97278434e-02, -2.29965821e-01,  2.31997147e-01, -7.79737979e-02,\n",
              "       -6.28169030e-02,  1.91688016e-02, -5.28665781e-01,  6.72648787e-01,\n",
              "       -6.24377966e-01, -4.00406986e-01, -5.96049547e-01, -2.36702502e-01,\n",
              "       -3.99316788e-01,  1.28545642e-01,  1.48642242e-01,  1.73506886e-01,\n",
              "        1.11753814e-01,  2.72934318e-01, -2.52524674e-01,  5.44611156e-01,\n",
              "       -1.05807535e-01, -1.25714213e-01, -1.72412455e-01,  7.59004414e-01,\n",
              "        2.11241931e-01, -6.83045164e-02,  1.86681896e-01,  3.44729513e-01,\n",
              "        2.06828728e-01,  2.16837689e-01, -3.06082428e-01,  3.17912661e-02,\n",
              "       -6.06840998e-02, -5.06176939e-03, -3.42850029e-01, -1.12787917e-01,\n",
              "        9.04608548e-01, -1.81641728e-02,  8.59951675e-02, -2.52236784e-01,\n",
              "       -7.16888011e-02, -7.68972710e-02,  1.76883951e-01,  1.01140499e-01,\n",
              "       -9.52694640e-02, -1.04149673e-02, -1.20159209e-01, -2.81574339e-01,\n",
              "       -5.28982170e-02,  2.13690460e-01,  2.13988557e-01,  1.96016058e-01,\n",
              "       -2.96424210e-01,  6.93831369e-02,  1.39952347e-01, -1.70837075e-01,\n",
              "       -2.84243554e-01,  1.89043768e-02,  2.68874049e-01, -2.16616206e-02,\n",
              "        2.07922116e-01, -3.02362859e-01,  7.31573701e-01, -6.05247557e-01,\n",
              "        7.07090050e-02, -8.49115252e-02, -1.74208898e-02, -2.55815238e-01,\n",
              "        5.10075688e-01, -1.78077847e-01,  4.81059462e-01,  8.94372687e-02,\n",
              "        1.97536558e-01, -8.62634555e-03, -1.16424389e-01,  2.62940340e-02,\n",
              "       -3.52019131e-01,  2.34776035e-01,  2.29514048e-01, -2.11661533e-01,\n",
              "        1.61980361e-01, -1.38604976e-02,  1.30367264e-01, -1.23636954e-01,\n",
              "        2.86635995e-01,  4.63462323e-02,  4.41155061e-02,  1.22207947e-01,\n",
              "       -2.70230174e-01, -2.35640388e-02, -2.30695635e-01, -2.13926360e-01,\n",
              "       -1.07141927e-01, -2.48932377e-01, -4.04067606e-01, -3.45602065e-01,\n",
              "        3.29385370e-01,  1.71417311e-01, -2.88306952e-01,  2.29240414e-02,\n",
              "       -5.81075400e-02, -1.53080806e-01,  3.80524397e-01,  3.99761111e-01,\n",
              "        1.12057760e-01, -1.01401061e-01, -2.24265367e-01, -4.06315029e-02,\n",
              "        2.57444471e-01,  8.24536290e-03, -1.09660007e-01, -3.13585391e-03,\n",
              "       -5.06303012e-01,  1.71887785e-01,  2.31565014e-01, -1.07475616e-01,\n",
              "       -2.69624144e-01,  2.81974405e-01, -4.97922301e-01,  9.29358453e-02],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# complete the code\n",
        "sentence = \"I really love going to the local park on Sunday mornings because the air is fresh and the birds are always singing.\"\n",
        "embedding = model.encode(sentence)\n",
        "embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql9pFPX4SsnZ"
      },
      "source": [
        "Create vector representations for several text sentences. Place the text strings in a list and use this list as an argument. Use 8-10 sentences of 20-25 words each.  Call the 'encode()' method on the model object with the list of sentences as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "t0uEOYZDTvdr"
      },
      "outputs": [],
      "source": [
        "sentences_list = [\n",
        "    \"My grandmother always says that the best way to start your day is with a hot cup of tea and a very long walk.\",\n",
        "    \"If you want to grow a healthy garden in your backyard, you need to make sure the soil is rich and you water daily.\",\n",
        "    \"Last summer we decided to drive across the whole country and we saw so many beautiful mountains and small towns along the dusty road.\",\n",
        "    \"I forgot to bring my umbrella to work today and I got completely soaked while I was waiting for the bus in the rain.\",\n",
        "    \"The little bakery on the corner of the street smells like fresh bread every single morning and it always makes me feel very hungry.\",\n",
        "    \"Whenever I feel stressed out after a long day at the office, I like to sit on the couch and listen to some quiet music.\",\n",
        "    \"Learning how to cook a really good meal for your friends is a great skill that will make everyone happy at the dinner table.\",\n",
        "    \"The kids were playing soccer in the middle of the field until the sun went down and their parents called them home for dinner.\",\n",
        "    \"I bought a new pair of running shoes yesterday because I want to start training for a big race that happens in the city.\",\n",
        "    \"Our old dog loves to sleep in the sun by the window and he usually stays there for the entire afternoon without moving at all.\"\n",
        "]\n",
        "\n",
        "list_embeddings = model.encode(sentences_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIATXYYKWNSe"
      },
      "source": [
        "#**Definition of semantic textual similaritye**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "addEfKLoXawa"
      },
      "source": [
        "Import 'util' module from sentence_transformers library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IDwL4gFsXogP"
      },
      "outputs": [],
      "source": [
        "# place your code here\n",
        "from sentence_transformers import util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPbGmfW4YJoZ"
      },
      "source": [
        "You can calculate the cosine similarity of the vector representations of our sentences using the 'cos_sim()' function from the util module.\n",
        "Example: sim = util.cos_sim(embedding_1, embedding_2). Calculate the cosine similarity for any two sentences from your list.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jtN5ElQKZYor"
      },
      "outputs": [],
      "source": [
        "# place your code here\n",
        "sim = util.cos_sim(list_embeddings[0], list_embeddings[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZPd8fUmazhu"
      },
      "source": [
        "Write and test a function named 'cos_similarity_calculation' that determines the semantic similarity between the sentences in your list and any text sentence using their vector representations and the cosine distance as a similarity measure.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gZuUCPGBuswG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity Scores:\n",
            "tensor([[0.5354, 0.2076, 0.3226, 0.2386, 0.3413, 0.2479, 0.0670, 0.0334, 0.3145,\n",
            "         0.2148]])\n"
          ]
        }
      ],
      "source": [
        "def cos_similarity_calculation(new_sentence, existing_list, model_obj):\n",
        "    new_embedding = model_obj.encode(new_sentence)\n",
        "    list_embeddings = model_obj.encode(existing_list)\n",
        "    similarity_scores = util.cos_sim(new_embedding, list_embeddings)\n",
        "    \n",
        "    return similarity_scores\n",
        "\n",
        "test_sentence = \"I love being outdoors and taking walks in the morning.\"\n",
        "scores = cos_similarity_calculation(test_sentence, sentences_list, model)\n",
        "\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ysHatbf2IdC"
      },
      "source": [
        "Create a function that determines the cosine similarity between a vector and a batch of vectors using the cosine distance formula and the numpy library. Add code to demonstrate how to use this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4R0iPr72096H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5853768  0.2540541  0.3158961  0.15698972 0.27366385 0.06570551\n",
            " 0.06971239 0.18077761 0.18471509 0.1815997 ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def manual_cosine_similarity(target_vector, vector_batch):\n",
        "    dot_product = np.dot(vector_batch, target_vector)\n",
        "    norm_target = np.linalg.norm(target_vector)\n",
        "    norm_batch = np.linalg.norm(vector_batch, axis=1)\n",
        "    similarities = dot_product / (norm_target * norm_batch)\n",
        "    \n",
        "    return similarities\n",
        "\n",
        "target_vec = model.encode(\"It is a beautiful day for a walk.\")\n",
        "manual_scores = manual_cosine_similarity(target_vec, list_embeddings)\n",
        "\n",
        "print(manual_scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
